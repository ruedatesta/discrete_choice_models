{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ce72a7d6",
   "metadata": {},
   "source": [
    "#  Discrete Choice Dynamic Programming\n",
    "## A Dynamic Probit Model\n",
    "\n",
    "So far, we were working in *static* problems when the agent has to decide between alternatives that do not involve a dynamic nature.\n",
    "In this lecture, we are going to cover a very simple example of Discrete Choice Dynamic Programming were time is another *state variable*. Again and for simplification, the decision space is minimal so we can focus on the innovation with respect to previous lecture: time.\n",
    "\n",
    "Assume an agent $n \\in N$ has to decide between two alternatives, working $(i=1)$ or leisure $(i=0)$. The *current* utility can be writen as\n",
    "\n",
    "$U_{n1}=\\beta x_n+\\varepsilon_{n1} $ if the agent chose to work\n",
    "\n",
    "$U_{n0}=\\mu +\\varepsilon_{n0} $ if the agent chose to do not work, i.e., leisure.\n",
    "\n",
    "However, the agent cares about future. Future is uncertain and there is no perfect forseight, so the agent has to form an *expectation*. The maximization problem of the agent can be thought as the maximization of current utility plus expected utility from tomorrow to the last day. The value function of this agent at time $t<T$ reads\n",
    "\n",
    "$V(t,d;\\varepsilon_t) =  max \\{ U_{n1}-U_{n0} + EV_m(t+1,d;\\varepsilon_{t+1}),EV_m(t+1,d+1;\\varepsilon_{t+1})\\}$\n",
    "\n",
    "And for the last day, $t=T$\n",
    "\n",
    "$V(T,d;\\varepsilon_T) =  max \\{ U_{n1}-U_{n0} +\\gamma \\pi(d)+ EV_m(1,0;\\varepsilon_{t+1,m+1}),\\gamma \\pi(d+1)+EV_m(1,0;\\varepsilon_{t+1,m+1})\\}$\n",
    "\n",
    "How do we solve this value function? *Backward iteration*.\n",
    "\n",
    "At time t=T, the terms $EV_m(1,0;\\varepsilon_{t+1,m+1})\\}$ enters at both sides of the maximization bracket. \n",
    "\n",
    "Let's assume a month has a maximum of 5 days. The Prob is now a matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e97c6f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots, Distributions, Random\n",
    "using DataFrames, CSV\n",
    "using Optim\n",
    "\n",
    "## Set Parameters and Distributions\n",
    "β=0.03;\n",
    "pm=0; # Probability of being fired\n",
    "P=3.0; # Non-pecunary cost\n",
    "μ=4.0;\n",
    "sim=100; # Number of simulated teachers\n",
    "dist=Normal(); # Dist of error term\n",
    "trdist(l)=truncated(dist,l, Inf); # Truncated Normal dist fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2212a19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "payment(d,treat=1,M=10)=treat*(500+50*max(0,d-M))+(1-treat)*1000; # Payment schedule for treated and control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9f6e1d6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5×5 Matrix{Float64}:\n",
       " NaN  NaN  NaN  NaN  NaN\n",
       " NaN  NaN  NaN  NaN  NaN\n",
       " NaN  NaN  NaN  NaN  NaN\n",
       " NaN  NaN  NaN  NaN  NaN\n",
       " NaN  NaN  NaN  NaN  NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Tm=5;\n",
    "ϵ_th=fill(NaN, Tm, Tm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "94e23bcb",
   "metadata": {},
   "source": [
    "For the last day, we could have worked zero days, one day, two days, three days or four days.\n",
    "For zero dyas, the payment would be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9df5e3d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ϵ_th[Tm,1]=-μ+P+β*(payment(1)-payment(0))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a726ef9f",
   "metadata": {},
   "source": [
    "For zero days to 4 days, the thresholds are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "02aadbd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Vector{Float64}:\n",
       " -1.0\n",
       " -1.0\n",
       " -1.0\n",
       " -1.0\n",
       " -1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for d=0:4\n",
    "    ϵ_th[Tm,d+1]=-μ+P+β*(payment(d+1)-payment(d))\n",
    "end\n",
    "ϵ_th[end,:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d11da5e4",
   "metadata": {},
   "source": [
    "If we extend the number of days to 30 days, we will have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b70bba39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30-element Vector{Float64}:\n",
       " -1.0\n",
       " -1.0\n",
       " -1.0\n",
       " -1.0\n",
       " -1.0\n",
       " -1.0\n",
       " -1.0\n",
       " -1.0\n",
       " -1.0\n",
       " -1.0\n",
       "  ⋮\n",
       "  0.5\n",
       "  0.5\n",
       "  0.5\n",
       "  0.5\n",
       "  0.5\n",
       "  0.5\n",
       "  0.5\n",
       "  0.5\n",
       "  0.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Tm=30;\n",
    "ϵ_th=fill(NaN, Tm, Tm)\n",
    "for d=0:Tm-1\n",
    "    ϵ_th[Tm,d+1]=-μ+P+β*(payment(d+1)-payment(d))\n",
    "end\n",
    "ϵ_th[end,:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bc22dff0",
   "metadata": {},
   "source": [
    "Once we computed the thresholds for the last day, we can assign probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2e5728da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30-element Vector{Float64}:\n",
       " 0.15865525393145702\n",
       " 0.15865525393145702\n",
       " 0.15865525393145702\n",
       " 0.15865525393145702\n",
       " 0.15865525393145702\n",
       " 0.15865525393145702\n",
       " 0.15865525393145702\n",
       " 0.15865525393145702\n",
       " 0.15865525393145702\n",
       " 0.15865525393145702\n",
       " ⋮\n",
       " 0.6914624612740131\n",
       " 0.6914624612740131\n",
       " 0.6914624612740131\n",
       " 0.6914624612740131\n",
       " 0.6914624612740131\n",
       " 0.6914624612740131\n",
       " 0.6914624612740131\n",
       " 0.6914624612740131\n",
       " 0.6914624612740131"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Pr=fill(NaN, Tm, Tm)\n",
    "ϵ_th=fill(NaN, Tm, Tm)\n",
    "for d=0:Tm-1\n",
    "    ϵ_th[Tm,d+1]=-μ+P+β*(payment(d+1)-payment(d));\n",
    "    Pr[Tm,d+1]=cdf(dist,ϵ_th[Tm,d+1]);\n",
    "end\n",
    "Pr[end,:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8d3de8f3",
   "metadata": {},
   "source": [
    "And finally, we can compute the value function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4f95883a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Pr=fill(NaN, Tm, Tm);\n",
    "ϵ_th=fill(NaN, Tm, Tm);\n",
    "V=fill(NaN,Tm, Tm);\n",
    "for d=0:Tm-1\n",
    "    ϵ_th[Tm,d+1]=-μ+P+β*(payment(d+1)-payment(d));\n",
    "    Pr[Tm,d+1]=cdf(dist,ϵ_th[Tm,d+1]);\n",
    "    V[Tm,d+1]=(1-Pr[Tm,d+1])*(μ-P+β*payment(d)+mean(trdist(ϵ_th[Tm,d+1])))+Pr[Tm,d+1]*(β*payment(d+1))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "aaaf169e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "probs (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function probs(β::Float64,μ::Float64) # Probability of working\n",
    "    Pr=fill(NaN, Tm, Tm); #Probability matrix for L=0, work\n",
    "    ϵ_th=fill(NaN, Tm, Tm); # Threshold matrix for L=0, work\n",
    "    V=fill(NaN, Tm, Tm); # Value funtion matrix\n",
    "        for t=Tm:-1:1\n",
    "            if t==Tm # Last day\n",
    "                for d=0:Tm-1\n",
    "                    ϵ_th[Tm,d+1]=-μ+P+β*(payment(d+1)-payment(d));\n",
    "                    Pr[Tm,d+1]=cdf(dist,ϵ_th[Tm,d+1]);\n",
    "                    V[Tm,d+1]=(1-Pr[Tm,d+1])*(μ-P+β*payment(d)+mean(trdist(ϵ_th[Tm,d+1])))+\n",
    "                    Pr[Tm,d+1]*(β*payment(d+1))\n",
    "                end\n",
    "            else # From day 1 to Tm-1\n",
    "                for d=0:t-1\n",
    "                    ϵ_th[t,d+1]=-μ+P+V[t+1,d+2]-V[t+1,d+1]\n",
    "                    Pr[t,d+1]=cdf(dist,ϵ_th[t,d+1])\n",
    "                    V[t,d+1]=(1-Pr[t,d+1])*(μ-P+mean(trdist(ϵ_th[t,d+1]))+V[t+1,d+1])+\n",
    "                    Pr[t,d+1]*(V[t+1,d+2])\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    return Pr\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4e973b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30×30 Matrix{Float64}:\n",
       " 1.0  NaN    NaN    NaN    NaN    NaN    …  NaN    NaN    NaN    NaN    NaN\n",
       " 1.0    1.0  NaN    NaN    NaN    NaN       NaN    NaN    NaN    NaN    NaN\n",
       " 1.0    1.0    1.0  NaN    NaN    NaN       NaN    NaN    NaN    NaN    NaN\n",
       " 1.0    1.0    1.0    1.0  NaN    NaN       NaN    NaN    NaN    NaN    NaN\n",
       " 1.0    1.0    1.0    1.0    1.0  NaN       NaN    NaN    NaN    NaN    NaN\n",
       " 1.0    1.0    1.0    1.0    1.0    1.0  …  NaN    NaN    NaN    NaN    NaN\n",
       " 1.0    1.0    1.0    1.0    1.0    1.0     NaN    NaN    NaN    NaN    NaN\n",
       " 1.0    1.0    1.0    1.0    1.0    1.0     NaN    NaN    NaN    NaN    NaN\n",
       " 1.0    1.0    1.0    1.0    1.0    1.0     NaN    NaN    NaN    NaN    NaN\n",
       " 1.0    1.0    1.0    1.0    1.0    1.0     NaN    NaN    NaN    NaN    NaN\n",
       " ⋮                                  ⋮    ⋱    ⋮                         \n",
       " 0.5    0.5    1.0    1.0    1.0    1.0     NaN    NaN    NaN    NaN    NaN\n",
       " 0.5    0.5    0.5    1.0    1.0    1.0     NaN    NaN    NaN    NaN    NaN\n",
       " 0.5    0.5    0.5    0.5    1.0    1.0     NaN    NaN    NaN    NaN    NaN\n",
       " 0.5    0.5    0.5    0.5    0.5    1.0     NaN    NaN    NaN    NaN    NaN\n",
       " 0.5    0.5    0.5    0.5    0.5    0.5  …    1.0  NaN    NaN    NaN    NaN\n",
       " 0.5    0.5    0.5    0.5    0.5    0.5       1.0    1.0  NaN    NaN    NaN\n",
       " 0.5    0.5    0.5    0.5    0.5    0.5       1.0    1.0    1.0  NaN    NaN\n",
       " 0.5    0.5    0.5    0.5    0.5    0.5       1.0    1.0    1.0    1.0  NaN\n",
       " 0.5    0.5    0.5    0.5    0.5    0.5       1.0    1.0    1.0    1.0    1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "probs(0.5,3.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.2",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af1b59ba",
   "metadata": {},
   "source": [
    "# Brief introduction to Discrete Choice Dynamic Programming (DCDP)\n",
    "\n",
    "Applied work in the field of microeconomics can be roughly divided into reduced-form and structural approaches. In this notebook, I will present a brief and incomplete introduction to the structural approach using Julia.\n",
    "\n",
    "As a first definition, a Discrete Choice Dynamic Programming (DCDP) model is an individual decision model that involves discrete choices over time. Hence, this approach is well suited when the economic problem can be thought of as an individual agent solving a dynamic problem, where her options are countable and mutually exclusive.\n",
    "\n",
    "This is a big difference with continuous choice models, usually implemented in Macroeconomics. For instance, the Aygari model has its decision support over a continuous (how much should the agent save), and even though we could discretize the support, we would be aiming to solve a continuous support dynamic problem.\n",
    "\n",
    "Any time a researcher is intended to understand a discrete decision making process that evolves dynamically, a DCDP is potentially useful.\n",
    "\n",
    "The lecture is organized in the following way. The first model is a static version of a Logit model for a dichotomous decision, work or do not work. After, we are going to estimate these very same parameters but trhough simulation, a practice that would be the rule in any other model that does not present a close-form solution. Once we understand how to estimate this model, we are going to extend it allowing for dynamics decisions under uncertainty.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "818d1751",
   "metadata": {},
   "source": [
    "## The Logit model\n",
    "\n",
    "Assume an agent $n \\in N$ has to decide between two alternatives, working $(i=1)$ or leisure $(i=0)$. The utility can be writen as\n",
    "\n",
    "$U_{n1}=\\beta x_n+\\varepsilon_{n1} $ if the agent chose to work\n",
    "\n",
    "$U_{n0}=\\mu +\\varepsilon_{n0} $ if the agent chose to do not work, i.e., leisure.\n",
    "\n",
    "The utility of working can be written as a linear component plus an idiosyncratic shock. If an agent $n$ chooses to work, she achieves a utility that is a function of her education attainment $x$ plus a working-related shock. The parameter $\\beta$ indicates the premium for each year of education, a parameter we are interested in recover it.\n",
    "\n",
    "The utility of not-working can be written as a fixed component $\\mu$ plus a leisure-related idiosyncratic shock. The fixed component can be interpreted as unemployment insurance and for simplicity, we are assuming it does not vary between agents. This assumption can be relaxed easily.\n",
    "\n",
    "The shock $\\varepsilon_{nj}$, $j=\\{0,1\\}$ is i.i.d. and choice specific, meaning that the agent face as many shocks as decisions she can choose from. In this model, we are going to assume that these idiosyncratic shocks come from a Type I Extreme Value (T1EV) distribution, known as the Gumbel distribution.\n",
    "\n",
    "### Decision\n",
    "The agent has to decide between working or do not working. In doing so, she need to compare the utility reported by each alternative. The agent will work if\n",
    "\n",
    "$$U_{n1}>U_{n0}$$\n",
    "\n",
    "But how can we compare utilities if they include a random shock? We can express this relation in terms of probabilities, that is\n",
    "\n",
    "$$Pr(U_{n1}>U_{n0})$$\n",
    "\n",
    "Using the expression for the utilities, we have\n",
    "\n",
    "$$Pr(\\beta x_n+\\varepsilon_{n1}>\\mu +\\varepsilon_{n0})$$\n",
    "\n",
    "And after some manipulation, he have\n",
    "\n",
    "$$Pr(\\varepsilon_{n0}-\\varepsilon_{n1}<\\beta x_n-\\mu)$$\n",
    "\n",
    "Due to the fact that the error is iid T1EV, the term in the left distributes logistic.\n",
    "\n",
    "The cdf of a standard Logistic distribution is\n",
    "\n",
    "$$Pr(Z<z)=\\frac{1}{1+e^{-z}}$$\n",
    "\n",
    "With the change of variable $z=\\varepsilon_{n0}-\\varepsilon_{n1}$ we can express this probability as\n",
    "\n",
    "$$Pr(\\beta x_n-\\mu<z)=\\frac{1}{1+e^{-(\\beta x_n-\\mu)}}$$\n",
    "\n",
    "And pre-multiplying by $e^{\\beta x_n}$ this probability can be re-written in the following way\n",
    "\n",
    "$$Pr(\\beta x_n-\\mu<z)=\\frac{e^{\\beta x_n}}{e^{\\beta x_n}+e^{\\mu}}$$\n",
    "\n",
    "\n",
    "### Numerical example\n",
    "\n",
    "Let's simulate data on education for 1000 agents. For doing that, in Julia, we need to use `Plots`, `Distributions`, and `Random` packages. Let's set a seed so our results are replicable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f928191",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots, Distributions, Random, Optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699d1874",
   "metadata": {},
   "source": [
    "Now, we are going to set the parameters for our data simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61c436c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "β=0.5; # premium for education\n",
    "μ=2.0; # ui\n",
    "n=1000; # Number of individuals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a6a950",
   "metadata": {},
   "source": [
    "Assume that for this population, years of education is between 1 and 10 and a uniform distribution can describe its variation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5aac57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(3);\n",
    "x=rand(Uniform(1, 10),n);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734da423",
   "metadata": {},
   "source": [
    "Now, let's get draws from Gumbel distibution and create two vectors, one for the utility from working and the other for the utility from leisure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42b34ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(3);\n",
    "dist=Gumbel();\n",
    "ϵw=rand(dist,n);\n",
    "ϵn=rand(dist,n);\n",
    "\n",
    "uw=β*x+ϵw;\n",
    "un=ϵn.+μ;"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0f973f22",
   "metadata": {},
   "source": [
    "In a vector called `decision`, we are going to specify if each agent decided to work or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e891b2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision=zeros(n)\n",
    "for i=1:n\n",
    "    if uw[i]>un[i]\n",
    "        decision[i]=1\n",
    "    else\n",
    "        decision[i]=0\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d885d9b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.666"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean(decision)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a322f2c3",
   "metadata": {},
   "source": [
    "Becuase the error term distributes TIEV, the probability of choosing to work can be written as\n",
    "\n",
    "$$ P_{n1}=\\frac{e^{\\beta x_n}}{e^{\\beta x_n}+e^{\\mu}} $$\n",
    "\n",
    "In Julia, this can be coded as\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "274c09d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prob (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function prob(β,μ)\n",
    "    pr=exp.(β*x)./(exp.(μ).+exp.(β*x))\n",
    "end"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c5a02c21",
   "metadata": {},
   "source": [
    "With our simulated data and the probability function, the parameters to estimate are $\\theta=(\\mu, \\beta)$.\n",
    "\n",
    "The log-likelihood of this problem can be writen as\n",
    "\n",
    "$$LL(\\theta)=\\sum_n \\sum_i decision_{in} \\times P_{ni}$$\n",
    "\n",
    "A possible implementation in Julia can be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d701fdf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "logL_fn (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function logL_fn(θ) #LogL function\n",
    "    β=θ[1]\n",
    "    μ=θ[2]\n",
    "    logL=0\n",
    "    n=1000\n",
    "    pr=prob(β,μ)\n",
    "    for id=1:n \n",
    "        logL=logL+log(pr[id])*decision[id]+log(1-pr[id])*(1-decision[id])\n",
    "    end\n",
    "    return -(logL)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eebd87d",
   "metadata": {},
   "source": [
    "Finally, through a MLE we can estimate our parameters. In Julia, we need to define a guess and then using the Optim package, we can minimize the LL function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f032dd6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Vector{Float64}:\n",
       " 0.5212689322779547\n",
       " 1.9817678556653724"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "θguess=[0.4,1.0];\n",
    "res=optimize(logL_fn, θguess)\n",
    "θstar=Optim.minimizer(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f379b8c2",
   "metadata": {},
   "source": [
    "The parameters estimated are very close to the population parameters."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cee709e6",
   "metadata": {},
   "source": [
    "Go to lecture 2 [The Logit Model solved by simulation](https://github.com/ruedatesta/discrete_choice_models/blob/main/lectures/lec2_logit.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.2",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
